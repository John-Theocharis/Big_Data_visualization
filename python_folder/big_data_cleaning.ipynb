{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('claims-2002-2006_0.xls')\n",
    "df2 = pd.read_excel('claims-2007-2009_0.xls')\n",
    "df3 = pd.read_excel('claims-2010-2013_0.xls')\n",
    "df4 = pd.read_excel('claims-2014.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195596\n"
     ]
    }
   ],
   "source": [
    "# Count the rows for each dataframe\n",
    "num_rows_df1 = len(df1)\n",
    "num_rows_df2 = len(df2)\n",
    "num_rows_df3 = len(df3)\n",
    "num_rows_df4 = len(df4)\n",
    "\n",
    "# Sum the row counts\n",
    "total_num_rows = num_rows_df1 + num_rows_df2 + num_rows_df3 + num_rows_df4\n",
    "\n",
    "# Print the result\n",
    "print(total_num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect the columns of each dataframe in a set\n",
    "columns_1 = set(df1.columns)\n",
    "columns_2 = set(df2.columns)\n",
    "columns_3 = set(df3.columns)\n",
    "columns_4 = set(df4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns of df1: Index(['Claim Number', 'Date Received', 'Incident Date', 'Airport Code',\n",
      "       'Airport Name', 'Airline Name', 'Claim Type', 'Claim Site', 'Item',\n",
      "       'Claim Amount', 'Status', 'Close Amount', 'Disposition'],\n",
      "      dtype='object')\n",
      "Columns of df2: Index(['Claim Number', 'Date Received', 'Incident Date', 'Airport Code',\n",
      "       'Airport Name', 'Airline Name', 'Claim Type', 'Claim Site', 'Item',\n",
      "       'Claim Amount', 'Status', 'Close Amount', 'Disposition'],\n",
      "      dtype='object')\n",
      "Columns of df3: Index(['Claim Number', 'Date Received', 'Incident Date', 'Airport Code',\n",
      "       'Airport Name', 'Airline Name', 'Claim Type', 'Claim Site',\n",
      "       'Item Category', 'Close Amount', 'Disposition'],\n",
      "      dtype='object')\n",
      "Columns of df4: Index(['Claim Number', 'Date Received', 'Incident Date', 'Airport Code',\n",
      "       'Airport Name', 'Airline Name', 'Claim Type', 'Claim Site',\n",
      "       'Item Category', 'Close Amount', 'Disposition'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print the different columns\n",
    "print(\"Columns of df1:\", df1.columns)\n",
    "print(\"Columns of df2:\", df2.columns)\n",
    "print(\"Columns of df3:\", df3.columns)\n",
    "print(\"Columns of df4:\", df4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Item', 'Item Category', 'Claim Amount', 'Status'}\n"
     ]
    }
   ],
   "source": [
    "# Collect the columns of each dataframe in a set\n",
    "columns_1 = set(df1.columns)\n",
    "columns_2 = set(df2.columns)\n",
    "columns_3 = set(df3.columns)\n",
    "columns_4 = set(df4.columns)\n",
    "\n",
    "# Find the different columns \n",
    "different_columns = columns_1.difference(columns_2).union(columns_2.difference(columns_3)).union(columns_3.difference(columns_4)).union(\n",
    "columns_4.difference(columns_1))\n",
    "\n",
    "# Print the different columns for the 4 datasets\n",
    "print(different_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Disposition                                             Status\n",
      "0             Deny                                             Denied\n",
      "1             Deny                                             Denied\n",
      "2             Deny                                             Denied\n",
      "3             Deny                                             Denied\n",
      "4              NaN  Insufficient, one of the following items requi...\n",
      "5  Approve in Full                                           Approved\n",
      "6  Approve in Full                                           Approved\n",
      "7  Approve in Full                                           Approved\n",
      "8  Approve in Full                                           Approved\n",
      "9  Approve in Full                                           Approved\n"
     ]
    }
   ],
   "source": [
    "subset = df2.loc[0:9, ['Disposition', 'Status']]\n",
    "\n",
    "# Print the subset dataframe\n",
    "print(subset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item differences\n",
    "The differences in the columns from the datasets are 'Item Category', 'Item', 'Status' and 'Claim Amount'.\n",
    "\n",
    "Item category and item is the same so there going to take the same name. claim amound is only in dataset claims-2007-2009_0.xls and reports the amount of money the victim was asking . due to the fact that this column is only in 1 of our 4 datasets it will be deleted. Status again is only in claims-2007-2009_0.xls and contains the information of disposition among a few more details . so Status will be renamed disposition and the column disposition is goint to be deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"claim amount\" column from df2 and disposition for df2\n",
    "df1 = df1.drop(columns=['Claim Amount'])\n",
    "df1 = df1.drop(columns=['Disposition'])\n",
    "df1 = df1.rename(columns={'Status': 'Disposition'})\n",
    "\n",
    "# Drop the \"claim amount\" column from df2 and disposition for df2\n",
    "df2 = df2.drop(columns=['Claim Amount'])\n",
    "df2 = df2.drop(columns=['Disposition'])\n",
    "df2 = df2.rename(columns={'Status': 'Disposition'})\n",
    "\n",
    "\n",
    "# Rename the \"Item Category\" column to \"Item\" in df3\n",
    "df3 = df3.rename(columns={'Item Category': 'Item'})\n",
    "\n",
    "# Rename the \"Item Category\" column to \"Item\" in df4\n",
    "df4 = df4.rename(columns={'Item Category': 'Item'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "columns_1 = set(df1.columns)\n",
    "columns_2 = set(df2.columns)\n",
    "columns_3 = set(df3.columns)\n",
    "columns_4 = set(df4.columns)\n",
    "\n",
    "# Find the different columns \n",
    "different_columns = columns_1.difference(columns_2).union(columns_2.difference(columns_3)).union(columns_3.difference(columns_4)).union(\n",
    "columns_4.difference(columns_1))\n",
    "\n",
    "# Print the different columns for the 4 datasets to see any remaining differences\n",
    "print(different_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Claim Number        Date Received        Incident Date Airport Code   \n",
      "0       0909802M  2002-01-04 00:00:00  2002-12-12 00:00:00          EWR  \\\n",
      "1       0202417M  2002-02-02 00:00:00  2004-01-16 00:00:00          SEA   \n",
      "2       0202445M  2002-02-04 00:00:00  2003-11-26 00:00:00          STL   \n",
      "3       0909816M  2002-02-07 00:00:00  2003-01-06 00:00:00          MIA   \n",
      "4  2005032379513  2002-02-18 00:00:00  2005-02-05 00:00:00          MCO   \n",
      "\n",
      "                      Airport Name          Airline Name       Claim Type   \n",
      "0     Newark International Airport  Continental Airlines  Property Damage  \\\n",
      "1     Seattle-Tacoma International                   NaN  Property Damage   \n",
      "2  Lambert St. Louis International     American Airlines  Property Damage   \n",
      "3      Miami International Airport     American Airlines  Property Damage   \n",
      "4    Orlando International Airport          Delta (Song)  Property Damage   \n",
      "\n",
      "        Claim Site                                        Item Disposition   \n",
      "0       Checkpoint                                       Other    Approved  \\\n",
      "1  Checked Baggage   Luggage (all types including footlockers)     Settled   \n",
      "2  Checked Baggage                                 Cell Phones     Settled   \n",
      "3       Checkpoint   Luggage (all types including footlockers)    Approved   \n",
      "4       Checkpoint  Baby - Strollers, car seats, playpen, etc.    Approved   \n",
      "\n",
      "  Close Amount  \n",
      "0        350.0  \n",
      "1         50.0  \n",
      "2       227.92  \n",
      "3         50.0  \n",
      "4        84.79  \n",
      "Number of columns: 11\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 195596 entries, 0 to 8854\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   Claim Number   195596 non-null  object\n",
      " 1   Date Received  195337 non-null  object\n",
      " 2   Incident Date  193417 non-null  object\n",
      " 3   Airport Code   187076 non-null  object\n",
      " 4   Airport Name   187076 non-null  object\n",
      " 5   Airline Name   161226 non-null  object\n",
      " 6   Claim Type     187687 non-null  object\n",
      " 7   Claim Site     194860 non-null  object\n",
      " 8   Item           191634 non-null  object\n",
      " 9   Disposition    195595 non-null  object\n",
      " 10  Close Amount   185767 non-null  object\n",
      "dtypes: object(11)\n",
      "memory usage: 17.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the dataframes together\n",
    "final_df = pd.concat([df1, df2, df3, df4])\n",
    "print(final_df.head(5))\n",
    "\n",
    "print('Number of columns:', final_df.shape[1])\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The empty values for each column are: \n",
      " Claim Number         0\n",
      "Date Received      259\n",
      "Incident Date     2179\n",
      "Airport Code      8520\n",
      "Airport Name      8520\n",
      "Airline Name     34370\n",
      "Claim Type        7909\n",
      "Claim Site         736\n",
      "Item              3962\n",
      "Disposition          1\n",
      "Close Amount      9829\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "empty_values = final_df.isnull().sum()\n",
    "print(\"The empty values for each column are: \\n\",empty_values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Date Received and Incident Date will be converted to a datetime type. Then,  the date portion of the datetime will be extracted only using the dt.date attribute and assign it back to the same column.The argument errors='coerce' will replace invalid datetimes with NaT (not a datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Date Received'] = pd.to_datetime(final_df['Date Received'], errors='coerce').dt.date\n",
    "final_df['Incident Date'] = pd.to_datetime(final_df['Incident Date'], errors='coerce').dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of NaT values in the 'Date Received' column is: 270\n",
      "The number of NaT values in the 'Incident Date' column is: 2343\n"
     ]
    }
   ],
   "source": [
    "date_cols = ['Date Received', 'Incident Date']\n",
    "for col in date_cols:\n",
    "    na_count = final_df[col].isna().sum()\n",
    "    print(\"The number of NaT values in the '{}' column is: {}\".format(col, na_count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### droprows from 2002 2003 and 2004\n",
    "drop the rows that contain the years 2002-2003-2004 as we want the data from 2005 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Incident Date'] = pd.to_datetime(final_df['Incident Date'])\n",
    "final_df['Date Received'] = pd.to_datetime(final_df['Date Received'])\n",
    "mask = final_df['Incident Date'].dt.year > 2004\n",
    "final_df = final_df.loc[mask]\n",
    "\n",
    "mask = (final_df['Date Received'].dt.year >= 2005) & (final_df['Date Received'].dt.year <= 2014)\n",
    "final_df = final_df.loc[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2005 2006 2007 2008 2009 2010 2011 2012 2013 2014]\n",
      "[2005 2006 2007 2008 2009 2010 2011 2012 2013 2014]\n"
     ]
    }
   ],
   "source": [
    "years = final_df['Incident Date'].dt.year.unique()\n",
    "print(years)\n",
    "years = final_df['Date Received'].dt.year.unique()\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_df['Disposition'] = final_df['Disposition'].replace({'Approve in Full': 'Approved',\n",
    "                                               'Denied': 'Denied/Canceled',\n",
    "                                               'Settle': 'Settled',\n",
    "                                               'Canceled':'Denied/Canceled',\n",
    "                                               '-':'Denied/Canceled',\n",
    "                                               'Claim has been assigned for further investigation':'In review',\n",
    "                                               'Closed as a contractor claim':'Settled',\n",
    "                                               'Deny':'Denied/Canceled'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Approved' 'Denied/Canceled' 'Settled'\n",
      " 'Insufficient, one of the following items required: sum certain, statement of fact, signature, location of incident, and date.'\n",
      " 'In litigation' 'In review' 'Pending response from claimant']\n"
     ]
    }
   ],
   "source": [
    "unique_dispositions = final_df['Disposition'].unique()\n",
    "print(unique_dispositions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['-']\n"
     ]
    }
   ],
   "source": [
    "unique_string_values = final_df.loc[final_df['Close Amount'].apply(lambda x: isinstance(x, str)), 'Close Amount'].unique()\n",
    "print(unique_string_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataset is stored in a pandas DataFrame called 'final_df'\n",
    "final_df['Close Amount'] = final_df['Close Amount'].replace('-', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('final_dataframe.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "big_data_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
